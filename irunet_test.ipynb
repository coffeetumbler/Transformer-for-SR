{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f7400f-d74f-45e1-aab0-a8db6d069cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coffeetumbler/anaconda3/envs/sr_trans/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pytorch_model_summary\n",
    "\n",
    "from models.irunets import IRUNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b45bd8-3472-4fc5-85cd-cd0ded5526aa",
   "metadata": {},
   "source": [
    "## IRUNet Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b94cdf82-3f6d-4ea4-a2d7-76cdd136b856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------\n",
      "            Layer (type)                            Input Shape         Param #     Tr. Param #\n",
      "================================================================================================\n",
      "                Conv2d-1                       [1, 3, 192, 192]           1,344           1,344\n",
      "    TransformerEncoder-2                      [1, 192, 192, 48]         122,568         122,568\n",
      "     DownsamplingLayer-3                      [1, 192, 192, 48]          18,528          18,528\n",
      "    TransformerEncoder-4                        [1, 96, 96, 96]         699,480         699,480\n",
      "     DownsamplingLayer-5                        [1, 96, 96, 96]          73,920          73,920\n",
      "    TransformerEncoder-6                       [1, 48, 48, 192]       2,726,064       2,726,064\n",
      "     DownsamplingLayer-7                       [1, 48, 48, 192]         295,296         295,296\n",
      "    TransformerEncoder-8                       [1, 24, 24, 384]      14,347,392      14,347,392\n",
      "    TransformerDecoder-9     [1, 48, 48, 192], [1, 24, 24, 384]       4,074,096       4,074,096\n",
      "   TransformerDecoder-10      [1, 96, 96, 96], [1, 48, 48, 192]       1,041,720       1,041,720\n",
      "   TransformerDecoder-11     [1, 192, 192, 48], [1, 96, 96, 96]         181,352         181,352\n",
      "               Conv2d-12                      [1, 96, 192, 192]           2,595           2,595\n",
      "================================================================================================\n",
      "Total params: 23,584,355\n",
      "Trainable params: 23,584,355\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "            Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "===============================================================================\n",
      "                Conv2d-1     [1, 48, 192, 192]           1,344           1,344\n",
      "    TransformerEncoder-2     [1, 192, 192, 48]         122,568         122,568\n",
      "     DownsamplingLayer-3       [1, 96, 96, 96]          18,528          18,528\n",
      "    TransformerEncoder-4       [1, 96, 96, 96]         699,480         699,480\n",
      "     DownsamplingLayer-5      [1, 48, 48, 192]          73,920          73,920\n",
      "    TransformerEncoder-6      [1, 48, 48, 192]       2,726,064       2,726,064\n",
      "     DownsamplingLayer-7      [1, 24, 24, 384]         295,296         295,296\n",
      "    TransformerEncoder-8      [1, 24, 24, 384]      14,347,392      14,347,392\n",
      "    TransformerDecoder-9      [1, 48, 48, 192]       4,074,096       4,074,096\n",
      "   TransformerDecoder-10       [1, 96, 96, 96]       1,041,720       1,041,720\n",
      "   TransformerDecoder-11     [1, 192, 192, 48]         181,352         181,352\n",
      "               Conv2d-12      [1, 3, 192, 192]           2,595           2,595\n",
      "===============================================================================\n",
      "Total params: 23,584,355\n",
      "Trainable params: 23,584,355\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# d = 48\n",
    "device = torch.device('cuda')\n",
    "irunet = IRUNet(img_res=192, d_embed=48, n_layer=[4,6,6,8], hidden_dim_rate=4, version=1).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(irunet,\n",
    "                                    torch.zeros(1, 3, 192, 192, device=device),\n",
    "                                    show_input=True))\n",
    "\n",
    "print(pytorch_model_summary.summary(irunet,\n",
    "                                    torch.zeros(1, 3, 192, 192, device=device),\n",
    "                                    show_input=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ec4cbf-d1e2-4493-a01b-09f59b431a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------\n",
      "            Layer (type)                            Input Shape         Param #     Tr. Param #\n",
      "================================================================================================\n",
      "                Conv2d-1                       [1, 3, 192, 192]           1,120           1,120\n",
      "    TransformerEncoder-2                      [1, 192, 192, 40]          87,080          87,080\n",
      "     DownsamplingLayer-3                      [1, 192, 192, 40]          12,880          12,880\n",
      "    TransformerEncoder-4                        [1, 96, 96, 80]         491,640         491,640\n",
      "     DownsamplingLayer-5                        [1, 96, 96, 80]          51,360          51,360\n",
      "    TransformerEncoder-6                       [1, 48, 48, 160]       1,904,880       1,904,880\n",
      "     DownsamplingLayer-7                       [1, 48, 48, 160]         205,120         205,120\n",
      "    TransformerEncoder-8                       [1, 24, 24, 320]       9,994,880       9,994,880\n",
      "    TransformerDecoder-9     [1, 48, 48, 160], [1, 24, 24, 320]       2,845,488       2,845,488\n",
      "   TransformerDecoder-10      [1, 96, 96, 80], [1, 48, 48, 160]         731,544         731,544\n",
      "   TransformerDecoder-11     [1, 192, 192, 40], [1, 96, 96, 80]         128,648         128,648\n",
      "               Conv2d-12                      [1, 80, 192, 192]           2,163           2,163\n",
      "================================================================================================\n",
      "Total params: 16,456,803\n",
      "Trainable params: 16,456,803\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "            Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "===============================================================================\n",
      "                Conv2d-1     [1, 40, 192, 192]           1,120           1,120\n",
      "    TransformerEncoder-2     [1, 192, 192, 40]          87,080          87,080\n",
      "     DownsamplingLayer-3       [1, 96, 96, 80]          12,880          12,880\n",
      "    TransformerEncoder-4       [1, 96, 96, 80]         491,640         491,640\n",
      "     DownsamplingLayer-5      [1, 48, 48, 160]          51,360          51,360\n",
      "    TransformerEncoder-6      [1, 48, 48, 160]       1,904,880       1,904,880\n",
      "     DownsamplingLayer-7      [1, 24, 24, 320]         205,120         205,120\n",
      "    TransformerEncoder-8      [1, 24, 24, 320]       9,994,880       9,994,880\n",
      "    TransformerDecoder-9      [1, 48, 48, 160]       2,845,488       2,845,488\n",
      "   TransformerDecoder-10       [1, 96, 96, 80]         731,544         731,544\n",
      "   TransformerDecoder-11     [1, 192, 192, 40]         128,648         128,648\n",
      "               Conv2d-12      [1, 3, 192, 192]           2,163           2,163\n",
      "===============================================================================\n",
      "Total params: 16,456,803\n",
      "Trainable params: 16,456,803\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# d = 40\n",
    "device = torch.device('cuda')\n",
    "irunet = IRUNet(img_res=192, d_embed=40, n_layer=[4,6,6,8], hidden_dim_rate=4, version=1).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(irunet,\n",
    "                                    torch.zeros(1, 3, 192, 192, device=device),\n",
    "                                    show_input=True))\n",
    "\n",
    "print(pytorch_model_summary.summary(irunet,\n",
    "                                    torch.zeros(1, 3, 192, 192, device=device),\n",
    "                                    show_input=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7cf65f2-1cb2-438e-a981-7a03d017e2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------\n",
      "            Layer (type)                             Input Shape         Param #     Tr. Param #\n",
      "=================================================================================================\n",
      "              Identity-1                        [1, 3, 192, 192]               0               0\n",
      "                Conv2d-2                        [1, 3, 192, 192]           2,240           2,240\n",
      "    TransformerEncoder-3                       [1, 192, 192, 80]         162,390         162,390\n",
      "     DownsamplingLayer-4                       [1, 192, 192, 80]          51,360          51,360\n",
      "    TransformerEncoder-5                        [1, 96, 96, 160]         842,640         842,640\n",
      "     DownsamplingLayer-6                        [1, 96, 96, 160]         205,120         205,120\n",
      "    TransformerEncoder-7                        [1, 48, 48, 320]       4,985,520       4,985,520\n",
      "     DownsamplingLayer-8                        [1, 48, 48, 320]         819,840         819,840\n",
      "    TransformerEncoder-9                        [1, 24, 24, 640]      26,401,920      26,401,920\n",
      "   TransformerDecoder-10      [1, 48, 48, 320], [1, 24, 24, 640]       8,700,528       8,700,528\n",
      "   TransformerDecoder-11      [1, 96, 96, 160], [1, 48, 48, 320]       1,466,576       1,466,576\n",
      "   TransformerDecoder-12     [1, 192, 192, 80], [1, 96, 96, 160]         281,166         281,166\n",
      "               Conv2d-13                      [1, 160, 192, 192]           4,323           4,323\n",
      "=================================================================================================\n",
      "Total params: 43,923,623\n",
      "Trainable params: 43,923,623\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "            Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "===============================================================================\n",
      "              Identity-1      [1, 3, 192, 192]               0               0\n",
      "                Conv2d-2     [1, 80, 192, 192]           2,240           2,240\n",
      "    TransformerEncoder-3     [1, 192, 192, 80]         162,390         162,390\n",
      "     DownsamplingLayer-4      [1, 96, 96, 160]          51,360          51,360\n",
      "    TransformerEncoder-5      [1, 96, 96, 160]         842,640         842,640\n",
      "     DownsamplingLayer-6      [1, 48, 48, 320]         205,120         205,120\n",
      "    TransformerEncoder-7      [1, 48, 48, 320]       4,985,520       4,985,520\n",
      "     DownsamplingLayer-8      [1, 24, 24, 640]         819,840         819,840\n",
      "    TransformerEncoder-9      [1, 24, 24, 640]      26,401,920      26,401,920\n",
      "   TransformerDecoder-10      [1, 48, 48, 320]       8,700,528       8,700,528\n",
      "   TransformerDecoder-11      [1, 96, 96, 160]       1,466,576       1,466,576\n",
      "   TransformerDecoder-12     [1, 192, 192, 80]         281,166         281,166\n",
      "               Conv2d-13      [1, 3, 192, 192]           4,323           4,323\n",
      "===============================================================================\n",
      "Total params: 43,923,623\n",
      "Trainable params: 43,923,623\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# d = 48, hidden rate = 2\n",
    "device = torch.device('cuda')\n",
    "irunet = IRUNet(img_res=192, d_embed=80, n_layer=[3,4,6,8], hidden_dim_rate=2, version=1).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(irunet,\n",
    "                                    torch.zeros(1, 3, 192, 192, device=device),\n",
    "                                    show_input=True))\n",
    "\n",
    "print(pytorch_model_summary.summary(irunet,\n",
    "                                    torch.zeros(1, 3, 192, 192, device=device),\n",
    "                                    show_input=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bac37-e04a-47b9-a124-3f2f521f2b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sr_trans",
   "language": "python",
   "name": "sr_trans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
