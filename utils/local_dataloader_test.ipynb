{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Normalize\n",
    "import dataloader as DT\n",
    "from dataloader import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "실행시키지 말 것 dataset zip파일 압축 푸는 코드\n",
    "'''\n",
    "# import zipfile\n",
    "# DIV2K = zipfile.ZipFile('/home/lahj91/SR/DIV2K_valid_HR.zip')\n",
    "# DIV2K.extractall('/home/lahj91/SR/DIV2K')\n",
    "# DIV2K.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "실행시키지 말 것 data 이름 저장하는 코드\n",
    "'''\n",
    "# name = os.listdir('./SR_training_datasets/BSDS200')#해당주소에서 data 이름 list로 추출\n",
    "# df = pd.DataFrame(name, columns = ['name']) #열 이름 = name 으로 list name을 저장\n",
    "# df.to_csv(\"BSDS200_DataName.csv\", index=False) #csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "실행시키지 말 것 data 이름 저장하는 코드\n",
    "'''\n",
    "# name = os.listdir('./DIV2K/DIV2K_train_HR')\n",
    "# df = pd.DataFrame(name, columns = ['name']) #열 이름 = name 으로 list name을 저장\n",
    "# df.to_csv(\"DIV2K_train_DataName.csv\", index=False) #csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "실행시키지 말 것 data 이름 저장하는 코드\n",
    "'''\n",
    "# name = os.listdir('./DIV2K/DIV2K_valid_HR')\n",
    "# df = pd.DataFrame(name, columns = ['name']) #열 이름 = name 으로 list name을 저장\n",
    "# df.to_csv(\"DIV2K_valid_DataName.csv\", index=False) #csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "실행시키지 말 것 data 이름 저장하는 코드\n",
    "'''\n",
    "# name = os.listdir('/home/lahj91/SR/SR_testing_datasets/BSDS100')\n",
    "# df = pd.DataFrame(name, columns = ['name']) #열 이름 = name 으로 list name을 저장\n",
    "# df.to_csv(\"valid_BSDS200.csv\", index=False) #csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/lahj91/SR/local_dataloader_test.ipynb 셀 7\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=1'>2</a>\u001b[0m \u001b[39m실행시키지 말 것 data 이름 저장하는 코드\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=3'>4</a>\u001b[0m name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39m/home/lahj91/SR/SR_training_datasets/General100\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=4'>5</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(\u001b[39m\"\u001b[39;49m\u001b[39mgeneral100\u001b[39;49m\u001b[39m\"\u001b[39;49m, columns\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=5'>6</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(name, columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m#열 이름 = name 으로 list name을 저장\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=6'>7</a>\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mtrain_General100.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/pandas/core/frame.py:756\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[39m# For data is scalar\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 756\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataFrame constructor not properly called!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    758\u001b[0m     \u001b[39m# Argument 1 to \"ensure_index\" has incompatible type \"Collection[Any]\";\u001b[39;00m\n\u001b[1;32m    759\u001b[0m     \u001b[39m# expected \"Union[Union[Union[ExtensionArray, ndarray],\u001b[39;00m\n\u001b[1;32m    760\u001b[0m     \u001b[39m# Index, Series], Sequence[Any]]\"\u001b[39;00m\n\u001b[1;32m    761\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "'''\n",
    "실행시키지 말 것 data 이름 저장하는 코드\n",
    "'''\n",
    "name = os.listdir('/home/lahj91/SR/SR_training_datasets/General100')\n",
    "\n",
    "df = pd.DataFrame(\"general100\", columns=\"data\")\n",
    "df = pd.DataFrame(name, columns = ['name']) #열 이름 = name 으로 list name을 저장\n",
    "df.to_csv(\"train_General100.csv\", index=False) #csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "부가적인 함수들\n",
    "'''\n",
    "def img2tensor(img, normalize=True):\n",
    "    # handle gray image\n",
    "    if len(img.shape)==2:\n",
    "        img = img[:,:,np.newaxis]\n",
    "    img = np.transpose(img, axes=(2,0,1)).astype(np.float32)\n",
    "    if normalize:\n",
    "        img = img / img.max()\n",
    "    return torch.from_numpy(img)\n",
    "\n",
    "def tensor2img(tensor):\n",
    "    if len(tensor.shape)==2:\n",
    "        img = tensor.cpu().numpy()\n",
    "    elif len(tensor.shape)==3:\n",
    "        img = np.transpose(tensor.cpu().numpy(), axes=(1,2,0))\n",
    "    return img\n",
    "\n",
    "def read_img_as_tensor(img_path, img_size=224, normalize=True):\n",
    "    if isinstance(img_size, int):\n",
    "        img_size = (img_size, img_size)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img2tensor(img, normalize=normalize)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "from dataloader import get_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_dataloader(batch_size=16,\n",
    "                                    setting='train', \n",
    "                                    augmentation=True,\n",
    "                                    pin_memory=True,\n",
    "                                    SR_mode = 2,\n",
    "                                    data='DIV2K',\n",
    "                                    data_merge=True,\n",
    "                                    num_workers=0\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for items in data_loader:\n",
    "    items = items\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam = DT.dataset_SR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DIV2K'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3749, 0.3749, 0.3642,  ..., 0.2571, 0.2571, 0.2714],\n",
       "         [0.3678, 0.3607, 0.3678,  ..., 0.2678, 0.2642, 0.2714],\n",
       "         [0.3607, 0.3571, 0.3678,  ..., 0.2535, 0.2607, 0.2678],\n",
       "         ...,\n",
       "         [0.2535, 0.2535, 0.2500,  ..., 0.2464, 0.2464, 0.2393],\n",
       "         [0.2571, 0.2500, 0.2571,  ..., 0.2285, 0.2393, 0.2500],\n",
       "         [0.2393, 0.2393, 0.2393,  ..., 0.2393, 0.2393, 0.2500]],\n",
       "\n",
       "        [[0.4784, 0.4784, 0.4701,  ..., 0.3258, 0.3258, 0.3423],\n",
       "         [0.4701, 0.4619, 0.4701,  ..., 0.3382, 0.3299, 0.3382],\n",
       "         [0.4619, 0.4577, 0.4701,  ..., 0.3217, 0.3299, 0.3382],\n",
       "         ...,\n",
       "         [0.3588, 0.3588, 0.3546,  ..., 0.3052, 0.3052, 0.2969],\n",
       "         [0.3629, 0.3546, 0.3629,  ..., 0.2845, 0.2969, 0.3093],\n",
       "         [0.3423, 0.3423, 0.3423,  ..., 0.2969, 0.2969, 0.3093]],\n",
       "\n",
       "        [[0.3153, 0.3153, 0.3087,  ..., 0.2693, 0.2693, 0.2825],\n",
       "         [0.3087, 0.3022, 0.3087,  ..., 0.2792, 0.2726, 0.2792],\n",
       "         [0.3055, 0.2989, 0.3120,  ..., 0.2660, 0.2726, 0.2792],\n",
       "         ...,\n",
       "         [0.3087, 0.3087, 0.3055,  ..., 0.2529, 0.2529, 0.2463],\n",
       "         [0.3120, 0.3055, 0.3120,  ..., 0.2365, 0.2463, 0.2562],\n",
       "         [0.2956, 0.2956, 0.2956,  ..., 0.2463, 0.2463, 0.2562]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam.__getitem__(2)['origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name_list1 = pd.read_csv('./DataName/' + \"train\" + \"_\" + \"DIV2K\" + \".csv\")\n",
    "data_name_list2 = pd.read_csv('./DataName/' + \"train\" + \"_\" + \"General100\" + \".csv\")\n",
    "data_name_list3 = pd.read_csv('./DataName/' + \"train\" + \"_\" + \"BSDS200\" + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [data_name_list1,data_name_list2,data_name_list3]\n",
    "data_all=[]\n",
    "for i in list:\n",
    "    data_all.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all\n",
    "data_all = pd.concat(data_all, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIV2K</td>\n",
       "      <td>0706.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIV2K</td>\n",
       "      <td>0791.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIV2K</td>\n",
       "      <td>0027.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIV2K</td>\n",
       "      <td>0119.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIV2K</td>\n",
       "      <td>0481.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>BSDS200</td>\n",
       "      <td>78019.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>BSDS200</td>\n",
       "      <td>176019.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>BSDS200</td>\n",
       "      <td>22013.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>BSDS200</td>\n",
       "      <td>187039.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>BSDS200</td>\n",
       "      <td>12003.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         data        name\n",
       "0       DIV2K    0706.png\n",
       "1       DIV2K    0791.png\n",
       "2       DIV2K    0027.png\n",
       "3       DIV2K    0119.png\n",
       "4       DIV2K    0481.png\n",
       "...       ...         ...\n",
       "1095  BSDS200   78019.png\n",
       "1096  BSDS200  176019.png\n",
       "1097  BSDS200   22013.png\n",
       "1098  BSDS200  187039.png\n",
       "1099  BSDS200   12003.png\n",
       "\n",
       "[1100 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DIV2K'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name_list.iloc[0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import config\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "class dataset_SR(Dataset):\n",
    "    def __init__(self,\n",
    "                setting = \"train\",\n",
    "                augmentation = True,\n",
    "                SR_mode = 2,\n",
    "                data='DIV2K',\n",
    "                data_merge = False\n",
    "                ):\n",
    "        super(dataset_SR, self).__init__()\n",
    "        self.SR_mode = SR_mode\n",
    "        self.data = data\n",
    "        self.setting = setting\n",
    "        # if self.setting == 'val':\n",
    "        #     self.setting = 'test'\n",
    "        self.augmentation = augmentation\n",
    "        self.flip = 0.5\n",
    "        self.rotation = [cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_180, cv2.ROTATE_90_COUNTERCLOCKWISE]\n",
    "        self.degradation = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC, cv2.INTER_LANCZOS4]\n",
    "        self.channel_wise_noise = True\n",
    "        self.MODE_PATH = config.MODE_PATH\n",
    "        self.normalize_img = Normalize(mean=[0.406, 0.456, 0.485], std=[0.225, 0.224, 0.229])\n",
    "        self.prefix = self.MODE_PATH[self.setting]+ '/'+ self.data + '/'\n",
    "        self.data_merge = data_merge\n",
    "\n",
    "        if self.setting == \"train\":\n",
    "            self.DATA_LIST = config.TRAINING_DATA_LIST\n",
    "        elif self.setting == \"test\":\n",
    "            self.DATA_LIST = config.TEST_DATA_LIST\n",
    "        \n",
    "        if self.data_merge:\n",
    "            data_all = []\n",
    "            for i in self.DATA_LIST:\n",
    "                df = pd.read_csv('./DataName/' + self.setting + \"_\" + i + \".csv\")\n",
    "                data_all.append(df)\n",
    "            self.data_name_list = pd.concat(data_all, axis=0, ignore_index=True)\n",
    "        else:\n",
    "            self.data_name_list = pd.read_csv('./DataName/' + self.setting + \"_\" + self.data + \".csv\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_name_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.data_merge:\n",
    "            view_path = self.MODE_PATH[self.setting]+ '/' + self.data_name_list.iloc[idx]['data'] + '/' + self.data_name_list.iloc[idx]['name']\n",
    "        else:\n",
    "            view_path = self.prefix + self.data_name_list.iloc[idx]['name']\n",
    "        origin = cv2.imread(view_path, cv2.IMREAD_UNCHANGED).copy()\n",
    "        p, q = random.randint(0, origin.shape[0]-self.SR_mode*48), random.randint(0, origin.shape[1]-self.SR_mode*48)\n",
    "        origin = origin[p:p+self.SR_mode*48,  q:q+self.SR_mode*48] #random crop(96*96)으로 origin data 생성\n",
    "        if self.augmentation:\n",
    "            if self.channel_wise_noise: #channel-wise noise\n",
    "                pn = np.random.uniform(*[1 - 0.4, 1 + 0.4], size=(3))\n",
    "                origin = np.minimum(255., np.maximum(0., origin * pn[np.newaxis, np.newaxis, :]))\n",
    "            if random.random() < self.flip: #좌우반전\n",
    "                origin = cv2.flip(origin, 1)\n",
    "            if self.rotation != False: #rotation\n",
    "                rd = random.random()\n",
    "                if rd < 3/4:\n",
    "                    origin = cv2.rotate(origin, random.choice(self.rotation))\n",
    "            degraded = cv2.resize(origin, dsize=(48,48), interpolation=random.choice(self.degradation)) \n",
    "        else:\n",
    "            degraded = cv2.resize(origin, dsize=(48,48), interpolation=cv2.INTER_CUBIC)\n",
    "        interpolated = cv2.resize(degraded, dsize=(self.SR_mode*48,self.SR_mode*48), interpolation=cv2.INTER_CUBIC) #bicubic으로 degraded를 96*96 size 복원 fx=0.5, fy=0.5,\n",
    "        items = {\"origin\" : torch.from_numpy(origin.transpose(2,0,1))/255, \"degraded\" : self.normalize_img(torch.from_numpy(degraded.transpose(2,0,1))/255), \"interpolated\" : self.normalize_img(torch.from_numpy(interpolated.transpose(2,0,1))/255)}\n",
    "        return items\n",
    "\n",
    "def get_dataloader(batch_size=16, setting='train', augmentation=True, pin_memory=True, num_workers=0, **kwargs): #num_workers는 hyperparameter tunning의 영역\n",
    "    if setting == 'train':\n",
    "        augmentation = True\n",
    "    elif setting == 'test':\n",
    "        augmentation = False\n",
    "    elif setting == 'valid':\n",
    "        setting = 'test'\n",
    "    dataloader = dataset_SR(setting=setting, augmentation=augmentation, **kwargs)\n",
    "    return DataLoader(dataloader, batch_size=batch_size, shuffle=augmentation, pin_memory=pin_memory, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam = dataset_SR(data_merge = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'origin': tensor([[[0.3341, 0.5214, 0.3745,  ..., 0.2056, 0.1946, 0.2020],\n",
       "          [0.3709, 0.5214, 0.4259,  ..., 0.1983, 0.2056, 0.2020],\n",
       "          [0.3452, 0.5214, 0.4810,  ..., 0.1946, 0.1946, 0.1946],\n",
       "          ...,\n",
       "          [0.2020, 0.4002, 0.4113,  ..., 0.1579, 0.1836, 0.1873],\n",
       "          [0.2166, 0.4370, 0.4076,  ..., 0.1873, 0.1983, 0.1726],\n",
       "          [0.2607, 0.4480, 0.4039,  ..., 0.2166, 0.2020, 0.1909]],\n",
       " \n",
       "         [[0.2848, 0.3916, 0.3026,  ..., 0.3204, 0.3255, 0.3280],\n",
       "          [0.3026, 0.3891, 0.3306,  ..., 0.3204, 0.3204, 0.3255],\n",
       "          [0.2823, 0.3967, 0.3611,  ..., 0.3229, 0.3179, 0.3153],\n",
       "          ...,\n",
       "          [0.2289, 0.3331, 0.3407,  ..., 0.1780, 0.1958, 0.2009],\n",
       "          [0.2390, 0.3535, 0.3382,  ..., 0.1983, 0.1983, 0.1907],\n",
       "          [0.2619, 0.3636, 0.3382,  ..., 0.2187, 0.2085, 0.2009]],\n",
       " \n",
       "         [[0.6430, 0.7832, 0.5560,  ..., 0.5560, 0.5560, 0.5560],\n",
       "          [0.6866, 0.7929, 0.6092,  ..., 0.5512, 0.5463, 0.5512],\n",
       "          [0.6382, 0.7929, 0.6769,  ..., 0.5463, 0.5415, 0.5367],\n",
       "          ...,\n",
       "          [0.5850, 0.7591, 0.7591,  ..., 0.4787, 0.5077, 0.5125],\n",
       "          [0.6044, 0.7881, 0.7591,  ..., 0.5077, 0.5125, 0.4932],\n",
       "          [0.6479, 0.8026, 0.7591,  ..., 0.5415, 0.5222, 0.5077]]],\n",
       "        dtype=torch.float64),\n",
       " 'degraded': tensor([[[ 0.1376, -0.6661, -1.1680,  ..., -1.0293, -0.9069, -0.9109],\n",
       "          [ 0.2110, -0.3683, -1.2496,  ..., -0.8824, -0.9109, -0.9354],\n",
       "          [ 0.4966, -0.3112, -1.3434,  ..., -0.9069, -0.9436, -0.8130],\n",
       "          ...,\n",
       "          [-0.3234,  0.1621, -0.3846,  ..., -0.8783, -0.9762, -0.9069],\n",
       "          [-0.4662, -0.0786, -0.4050,  ..., -1.0578, -1.1394, -1.0129],\n",
       "          [-0.2908, -0.2214, -0.3642,  ..., -1.0864, -1.0007, -0.9558]],\n",
       " \n",
       "         [[-0.5089, -1.0453, -1.4114,  ..., -0.8353, -0.5997, -0.5855],\n",
       "          [-0.4692, -0.8608, -1.4937,  ..., -0.6281, -0.5997, -0.6025],\n",
       "          [-0.2932, -0.8239, -1.5334,  ..., -0.6082, -0.6111, -0.5685],\n",
       "          ...,\n",
       "          [-0.7274, -0.4550, -0.7955,  ..., -1.0963, -1.1645, -1.1191],\n",
       "          [-0.7785, -0.5770, -0.8012,  ..., -1.2212, -1.2610, -1.1701],\n",
       "          [-0.6763, -0.6480, -0.7700,  ..., -1.2099, -1.1616, -1.1446]],\n",
       " \n",
       "         [[ 1.0543, -0.1650, -0.5503,  ..., -0.1280,  0.3154,  0.2943],\n",
       "          [ 1.1071,  0.1095, -0.7667,  ...,  0.2679,  0.2837,  0.2679],\n",
       "          [ 1.4080,  0.1570, -0.9197,  ...,  0.2679,  0.2468,  0.3312],\n",
       "          ...,\n",
       "          [ 0.9224,  1.2707,  0.7535,  ...,  0.1992,  0.1148,  0.1517],\n",
       "          [ 0.8168,  1.0860,  0.7323,  ...,  0.0303, -0.0383,  0.0726],\n",
       "          [ 0.9857,  1.0121,  0.7851,  ...,  0.0040,  0.0673,  0.1042]]],\n",
       "        dtype=torch.float64),\n",
       " 'interpolated': tensor([[[ 0.2171, -0.0414, -0.4614,  ..., -0.8923, -0.9031, -0.9086],\n",
       "          [ 0.2228, -0.0041, -0.3705,  ..., -0.9005, -0.9145, -0.9223],\n",
       "          [ 0.2282,  0.0544, -0.2223,  ..., -0.9141, -0.9344, -0.9466],\n",
       "          ...,\n",
       "          [-0.4737, -0.3632, -0.1779,  ..., -1.1038, -1.0385, -0.9992],\n",
       "          [-0.3501, -0.2981, -0.2102,  ..., -1.0180, -0.9856, -0.9656],\n",
       "          [-0.2761, -0.2598, -0.2316,  ..., -0.9670, -0.9544, -0.9460]],\n",
       " \n",
       "         [[-0.4549, -0.6262, -0.9041,  ..., -0.5689, -0.5783, -0.5820],\n",
       "          [-0.4535, -0.6042, -0.8471,  ..., -0.5773, -0.5859, -0.5897],\n",
       "          [-0.4535, -0.5697, -0.7541,  ..., -0.5911, -0.5987, -0.6027],\n",
       "          ...,\n",
       "          [-0.7771, -0.7190, -0.6211,  ..., -1.2325, -1.1882, -1.1614],\n",
       "          [-0.7081, -0.6816, -0.6360,  ..., -1.1764, -1.1592, -1.1485],\n",
       "          [-0.6666, -0.6594, -0.6460,  ..., -1.1430, -1.1420, -1.1409]],\n",
       " \n",
       "         [[ 1.1798,  0.7789,  0.1228,  ...,  0.3653,  0.3191,  0.2948],\n",
       "          [ 1.1781,  0.8101,  0.2100,  ...,  0.3409,  0.3036,  0.2836],\n",
       "          [ 1.1711,  0.8582,  0.3521,  ...,  0.3008,  0.2775,  0.2643],\n",
       "          ...,\n",
       "          [ 0.8222,  0.9014,  1.0356,  ..., -0.0113,  0.0470,  0.0821],\n",
       "          [ 0.9354,  0.9703,  1.0309,  ...,  0.0543,  0.0827,  0.1002],\n",
       "          [ 1.0034,  1.0112,  1.0267,  ...,  0.0932,  0.1037,  0.1107]]],\n",
       "        dtype=torch.float64)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam.__getitem__(1099)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('SR': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d9270d579d8ebbe73ed8b49f1a59e893b9664ab3a1c0ee56f3974d12cb24dc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
