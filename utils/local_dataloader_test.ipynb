{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahj91/anaconda3/envs/SR/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Normalize\n",
    "import dataloader as DT\n",
    "from dataloader import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "실행시키지 말 것 dataset zip파일 압축 푸는 코드\n",
    "'''\n",
    "# import zipfile\n",
    "# DIV2K = zipfile.ZipFile('/home/lahj91/SR/DIV2K_valid_HR.zip')\n",
    "# DIV2K.extractall('/home/lahj91/SR/DIV2K')\n",
    "# DIV2K.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "실행시키지 말 것 data 이름 저장하는 코드\n",
    "'''\n",
    "# name = os.listdir('./SR_training_datasets/BSDS200')#해당주소에서 data 이름 list로 추출\n",
    "# df = pd.DataFrame(name, columns = ['name']) #열 이름 = name 으로 list name을 저장\n",
    "# df.to_csv(\"BSDS200_DataName.csv\", index=False) #csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "실행시키지 말 것 data 이름 저장하는 코드\n",
    "'''\n",
    "# name = os.listdir('./DIV2K/DIV2K_train_HR')\n",
    "# df = pd.DataFrame(name, columns = ['name']) #열 이름 = name 으로 list name을 저장\n",
    "# df.to_csv(\"DIV2K_train_DataName.csv\", index=False) #csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "실행시키지 말 것 data 이름 저장하는 코드\n",
    "'''\n",
    "# name = os.listdir('./DIV2K/DIV2K_valid_HR')\n",
    "# df = pd.DataFrame(name, columns = ['name']) #열 이름 = name 으로 list name을 저장\n",
    "# df.to_csv(\"DIV2K_valid_DataName.csv\", index=False) #csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "실행시키지 말 것 data 이름 저장하는 코드\n",
    "'''\n",
    "# name = os.listdir('/home/lahj91/SR/SR_testing_datasets/BSDS100')\n",
    "# df = pd.DataFrame(name, columns = ['name']) #열 이름 = name 으로 list name을 저장\n",
    "# df.to_csv(\"valid_BSDS200.csv\", index=False) #csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/lahj91/SR/local_dataloader_test.ipynb 셀 7\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=1'>2</a>\u001b[0m \u001b[39m실행시키지 말 것 data 이름 저장하는 코드\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=3'>4</a>\u001b[0m name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39m/home/lahj91/SR/SR_training_datasets/General100\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=4'>5</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(\u001b[39m\"\u001b[39;49m\u001b[39mgeneral100\u001b[39;49m\u001b[39m\"\u001b[39;49m, columns\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=5'>6</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(name, columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m#열 이름 = name 으로 list name을 저장\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.28.146/home/lahj91/SR/local_dataloader_test.ipynb#ch0000013vscode-remote?line=6'>7</a>\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mtrain_General100.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/pandas/core/frame.py:756\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[39m# For data is scalar\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 756\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataFrame constructor not properly called!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    758\u001b[0m     \u001b[39m# Argument 1 to \"ensure_index\" has incompatible type \"Collection[Any]\";\u001b[39;00m\n\u001b[1;32m    759\u001b[0m     \u001b[39m# expected \"Union[Union[Union[ExtensionArray, ndarray],\u001b[39;00m\n\u001b[1;32m    760\u001b[0m     \u001b[39m# Index, Series], Sequence[Any]]\"\u001b[39;00m\n\u001b[1;32m    761\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "'''\n",
    "실행시키지 말 것 data 이름 저장하는 코드\n",
    "'''\n",
    "name = os.listdir('/home/lahj91/SR/SR_training_datasets/General100')\n",
    "\n",
    "df = pd.DataFrame(\"general100\", columns=\"data\")\n",
    "df = pd.DataFrame(name, columns = ['name']) #열 이름 = name 으로 list name을 저장\n",
    "df.to_csv(\"train_General100.csv\", index=False) #csv 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "부가적인 함수들\n",
    "'''\n",
    "def img2tensor(img, normalize=True):\n",
    "    # handle gray image\n",
    "    if len(img.shape)==2:\n",
    "        img = img[:,:,np.newaxis]\n",
    "    img = np.transpose(img, axes=(2,0,1)).astype(np.float32)\n",
    "    if normalize:\n",
    "        img = img / img.max()\n",
    "    return torch.from_numpy(img)\n",
    "\n",
    "def tensor2img(tensor):\n",
    "    if len(tensor.shape)==2:\n",
    "        img = tensor.cpu().numpy()\n",
    "    elif len(tensor.shape)==3:\n",
    "        img = np.transpose(tensor.cpu().numpy(), axes=(1,2,0))\n",
    "    return img\n",
    "\n",
    "def read_img_as_tensor(img_path, img_size=224, normalize=True):\n",
    "    if isinstance(img_size, int):\n",
    "        img_size = (img_size, img_size)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img2tensor(img, normalize=normalize)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahj91/anaconda3/envs/SR/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "from dataloader import get_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_dataloader(batch_size=5,\n",
    "                                    setting='valid', \n",
    "                                    augmentation=False,\n",
    "                                    pin_memory=True,\n",
    "                                    SR_mode = 2,\n",
    "                                    data='DIV2K',\n",
    "                                    data_merge=False,\n",
    "                                    num_workers=0\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1260_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/lahj91/SR/utils/local_dataloader_test.ipynb 셀 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m items \u001b[39min\u001b[39;00m data_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     items \u001b[39m=\u001b[39m items\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    560\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    563\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:47\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 47\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:74\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n\u001b[1;32m     73\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: default_collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m     75\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:74\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n\u001b[1;32m     73\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: default_collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m     75\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:74\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n\u001b[1;32m     73\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: default_collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m     75\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:74\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n\u001b[1;32m     73\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: default_collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m     75\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:74\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n\u001b[1;32m     73\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: default_collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m     75\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "\u001b[0;31mKeyError\u001b[0m: '1260_0'"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for items in data_loader:\n",
    "    items = items\n",
    "    i += 1\n",
    "    if i>1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items['item_origin'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam = DT.dataset_SR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DIV2K'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3749, 0.3749, 0.3642,  ..., 0.2571, 0.2571, 0.2714],\n",
       "         [0.3678, 0.3607, 0.3678,  ..., 0.2678, 0.2642, 0.2714],\n",
       "         [0.3607, 0.3571, 0.3678,  ..., 0.2535, 0.2607, 0.2678],\n",
       "         ...,\n",
       "         [0.2535, 0.2535, 0.2500,  ..., 0.2464, 0.2464, 0.2393],\n",
       "         [0.2571, 0.2500, 0.2571,  ..., 0.2285, 0.2393, 0.2500],\n",
       "         [0.2393, 0.2393, 0.2393,  ..., 0.2393, 0.2393, 0.2500]],\n",
       "\n",
       "        [[0.4784, 0.4784, 0.4701,  ..., 0.3258, 0.3258, 0.3423],\n",
       "         [0.4701, 0.4619, 0.4701,  ..., 0.3382, 0.3299, 0.3382],\n",
       "         [0.4619, 0.4577, 0.4701,  ..., 0.3217, 0.3299, 0.3382],\n",
       "         ...,\n",
       "         [0.3588, 0.3588, 0.3546,  ..., 0.3052, 0.3052, 0.2969],\n",
       "         [0.3629, 0.3546, 0.3629,  ..., 0.2845, 0.2969, 0.3093],\n",
       "         [0.3423, 0.3423, 0.3423,  ..., 0.2969, 0.2969, 0.3093]],\n",
       "\n",
       "        [[0.3153, 0.3153, 0.3087,  ..., 0.2693, 0.2693, 0.2825],\n",
       "         [0.3087, 0.3022, 0.3087,  ..., 0.2792, 0.2726, 0.2792],\n",
       "         [0.3055, 0.2989, 0.3120,  ..., 0.2660, 0.2726, 0.2792],\n",
       "         ...,\n",
       "         [0.3087, 0.3087, 0.3055,  ..., 0.2529, 0.2529, 0.2463],\n",
       "         [0.3120, 0.3055, 0.3120,  ..., 0.2365, 0.2463, 0.2562],\n",
       "         [0.2956, 0.2956, 0.2956,  ..., 0.2463, 0.2463, 0.2562]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam.__getitem__(2)['origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name_list1 = pd.read_csv('./DataName/' + \"train\" + \"_\" + \"DIV2K\" + \".csv\")\n",
    "data_name_list2 = pd.read_csv('./DataName/' + \"train\" + \"_\" + \"General100\" + \".csv\")\n",
    "data_name_list3 = pd.read_csv('./DataName/' + \"train\" + \"_\" + \"BSDS200\" + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [data_name_list1,data_name_list2,data_name_list3]\n",
    "data_all=[]\n",
    "for i in list:\n",
    "    data_all.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all\n",
    "data_all = pd.concat(data_all, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIV2K</td>\n",
       "      <td>0706.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIV2K</td>\n",
       "      <td>0791.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DIV2K</td>\n",
       "      <td>0027.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIV2K</td>\n",
       "      <td>0119.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIV2K</td>\n",
       "      <td>0481.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>BSDS200</td>\n",
       "      <td>78019.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>BSDS200</td>\n",
       "      <td>176019.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>BSDS200</td>\n",
       "      <td>22013.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>BSDS200</td>\n",
       "      <td>187039.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>BSDS200</td>\n",
       "      <td>12003.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         data        name\n",
       "0       DIV2K    0706.png\n",
       "1       DIV2K    0791.png\n",
       "2       DIV2K    0027.png\n",
       "3       DIV2K    0119.png\n",
       "4       DIV2K    0481.png\n",
       "...       ...         ...\n",
       "1095  BSDS200   78019.png\n",
       "1096  BSDS200  176019.png\n",
       "1097  BSDS200   22013.png\n",
       "1098  BSDS200  187039.png\n",
       "1099  BSDS200   12003.png\n",
       "\n",
       "[1100 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DIV2K'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name_list.iloc[0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "import config\n",
    "\n",
    "\n",
    "\n",
    "class dataset_SR(Dataset):\n",
    "    def __init__(self,\n",
    "                setting = \"train\",\n",
    "                augmentation = True,\n",
    "                SR_mode = 2,\n",
    "                data=\"DIV2K\",\n",
    "                data_merge = False\n",
    "                ):\n",
    "        super(dataset_SR, self).__init__()\n",
    "        self.SR_mode = SR_mode\n",
    "        self.img_size = SR_mode * 48\n",
    "        self.data = data\n",
    "        self.setting = setting\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.flip = 0.5\n",
    "        self.rotation = [cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_180, cv2.ROTATE_90_COUNTERCLOCKWISE]\n",
    "        self.degradation = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC, cv2.INTER_LANCZOS4]\n",
    "        self.channel_wise_noise = True\n",
    "        \n",
    "        self.MODE_PATH = config.MODE_PATH\n",
    "        self.normalize_img = Normalize(config.IMG_NORM_MEAN, config.IMG_NORM_STD)\n",
    "        self.prefix = self.MODE_PATH[self.setting] + self.data + '/'\n",
    "        self.data_merge = data_merge\n",
    "        self.intersection = config.PIXEL_INTERSECTION\n",
    "\n",
    "        if self.setting == \"train\":\n",
    "            self.DATA_LIST = config.TRAINING_DATA_LIST\n",
    "        else:\n",
    "            self.DATA_LIST = config.TEST_DATA_LIST\n",
    "\n",
    "            \n",
    "\n",
    "        if self.data_merge:\n",
    "            data_all = []\n",
    "            for i in self.DATA_LIST:\n",
    "                df = pd.read_csv(config.DATA_LIST_DIR + self.setting + \"_\" + i + \".csv\")\n",
    "                data_all.append(df)\n",
    "            self.data_name_list = pd.concat(data_all, axis=0, ignore_index=True)\n",
    "        else:\n",
    "            self.data_name_list = pd.read_csv(config.DATA_LIST_DIR + self.setting + \"_\" + self.data + \".csv\")\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_name_list)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.data_merge:\n",
    "            view_path = self.MODE_PATH[self.setting] + self.data_name_list.iloc[idx]['data'] + '/' + self.data_name_list.iloc[idx]['name']\n",
    "        else:\n",
    "            view_path = self.prefix + self.data_name_list.iloc[idx]['name']\n",
    "        origin = cv2.imread(view_path, cv2.IMREAD_UNCHANGED).copy()\n",
    "        if self.setting == \"valid\":\n",
    "            idx_x = [i for i in range(0,origin.shape[0]-self.img_size+1, self.img_size-self.intersection)]\n",
    "            if origin.shape[0]%(self.img_size) != 0:\n",
    "                idx_x = np.append(idx_x, origin.shape[0]-self.img_size)\n",
    "            idx_y = [i for i in range(0,origin.shape[1]-self.img_size+1, self.img_size-self.intersection)]\n",
    "            if origin.shape[1]%(self.img_size) != 0:\n",
    "                idx_y = np.append(idx_y, origin.shape[1]-self.img_size)\n",
    "            item_origin = {}\n",
    "            item_degraded = {}\n",
    "            for i in idx_x:\n",
    "                for j in idx_y:\n",
    "                    item_origin[\"{}_{}\".format(i,j)] = origin[i:i+self.img_size, j:j+self.img_size]\n",
    "                    item_degraded[\"{}_{}\".format(i,j)] = self.normalize_img(torch.from_numpy(cv2.resize(origin[i:i+self.img_size, j:j+self.img_size], dsize=(48,48), interpolation=cv2.INTER_CUBIC).transpose(2,0,1)).float() / 255)\n",
    "            items = {\"item_origin\" : item_origin, \"item_degraded\" : item_degraded}\n",
    "            return items\n",
    "\n",
    "        p, q = random.randint(0, origin.shape[0]-self.img_size), random.randint(0, origin.shape[1]-self.img_size)\n",
    "        origin = origin[p:p+self.img_size,  q:q+self.img_size] #random crop(96*96)으로 origin data 생성\n",
    "        if self.augmentation:\n",
    "            if self.channel_wise_noise: #channel-wise noise\n",
    "                pn = np.random.uniform(*[1 - 0.4, 1 + 0.4], size=(3))\n",
    "                origin = np.minimum(255., np.maximum(0., origin * pn[np.newaxis, np.newaxis, :]))\n",
    "            if random.random() < self.flip: #좌우반전\n",
    "                origin = cv2.flip(origin, 1)\n",
    "            if self.rotation != False: #rotation\n",
    "                rd = random.random()\n",
    "                if rd < 3/4:\n",
    "                    origin = cv2.rotate(origin, random.choice(self.rotation))\n",
    "            degraded = cv2.resize(origin, dsize=(48,48), interpolation=random.choice(self.degradation))\n",
    "            \n",
    "        else:\n",
    "            degraded = cv2.resize(origin, dsize=(48,48), interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "        interpolated = cv2.resize(degraded, dsize=(self.img_size,self.img_size), interpolation=cv2.INTER_CUBIC) #bicubic으로 degraded를 96*96 size 복원 fx=0.5, fy=0.5,\n",
    "\n",
    "        items = {}\n",
    "        items['origin'] = torch.from_numpy(origin.transpose(2,0,1)).float() / 255\n",
    "        items['degraded'] = self.normalize_img(torch.from_numpy(degraded.transpose(2,0,1)).float() / 255)\n",
    "        items['interpolated'] = self.normalize_img(torch.from_numpy(interpolated.transpose(2,0,1)).float() / 255)\n",
    "\n",
    "        return items\n",
    "\n",
    "    \n",
    "    \n",
    "def get_dataloader(batch_size=16, setting='train', augmentation=True, pin_memory=False, num_workers=0, **kwargs): #num_workers는 hyperparameter tunning의 영역\n",
    "    if setting == 'train':\n",
    "        augmentation = True\n",
    "    elif (setting == 'test') or (setting == 'valid'):\n",
    "        augmentation = False\n",
    "    dataloader = dataset_SR(setting=setting, augmentation=augmentation, **kwargs)\n",
    "    return DataLoader(dataloader, batch_size=batch_size, shuffle=augmentation, pin_memory=pin_memory, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam = dataset_SR(setting=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 48, 48])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam.__getitem__(0)['degraded'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 48, 48])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam.__getitem__(0)[\"item_degraded\"][\"0_0\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam.__getitem__(0)[\"item_degraded\"][\"0_0\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_dataloader = get_dataloader(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lahj91/SR/utils/local_dataloader_test.ipynb 셀 28\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwhile\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m A \u001b[39min\u001b[39;00m exam_dataloader:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m         items \u001b[39m=\u001b[39m A\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     i\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    560\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    563\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/SR/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home/lahj91/SR/utils/local_dataloader_test.ipynb 셀 28\u001b[0m in \u001b[0;36mdataset_SR.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m     view_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprefix \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_name_list\u001b[39m.\u001b[39miloc[idx][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m origin \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(view_path, cv2\u001b[39m.\u001b[39;49mIMREAD_UNCHANGED)\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetting \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B147.46.27.138/home/lahj91/SR/utils/local_dataloader_test.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m     idx_x \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,origin\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_size\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_size\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintersection)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "while i == 1:\n",
    "    for A in exam_dataloader:\n",
    "        items = A\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f0d6419a400>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = cv2.imread('/home/lahj91/SR/datasets/SR_testing_datasets/DIV2K/0801.png', cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1356, 2040, 3)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = origin.shape\n",
    "# size = [200, 200]\n",
    "SR_mode = 2\n",
    "intersection = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_x = [i for i in range(0,size[0]-SR_mode*48+1, SR_mode*48-intersection)]\n",
    "if size[0]%(SR_mode*48) != 0:\n",
    "    idx_x = np.append(idx_x, size[0]-48*SR_mode)\n",
    "idx_y = [i for i in range(0,size[1]-SR_mode*48+1, SR_mode*48-intersection)]\n",
    "if size[1]%(SR_mode*48) != 0:\n",
    "    idx_y = np.append(idx_y, size[1]-48*SR_mode)\n",
    "items = {}\n",
    "for i in idx_x:\n",
    "    for j in idx_y:\n",
    "        items[\"{}_{}\".format(i,j)] = origin[i:i+48*SR_mode, j:j+48*SR_mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 96, 3)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[\"0_0\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if size[0]%(SR_mode*48) == 0:\n",
    "    idx_x = np.append(idx_x, size[0]-48*SR_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 79, 96])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(idx_x, size[0]-48*SR_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('SR': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d9270d579d8ebbe73ed8b49f1a59e893b9664ab3a1c0ee56f3974d12cb24dc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
